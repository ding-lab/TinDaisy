#!/bin/bash

# Matthew Wyczalkowski <m.wyczalkowski@wustl.edu>
# https://dinglab.wustl.edu/

# TODO: implement query

read -r -d '' USAGE <<'EOF'
Register, query, and archive Cromwell run output

Usage:
  bash runtidy [options] [ CASE1 [CASE2 ...]]

Required options:

Optional options
-h: print usage information
-d: dry run: print commands but do not run
-v: verbose
-1: stop after one case processed.
-x TASK: Execute given task.  Values: 'query' (default), 'register', 'stash', 'finalize'
-k CASES_FN: file with list of all cases, one per line, used when CASE1 not defined. Default: dat/cases.dat
-l LOGD: directory where runtime output (CASE.out, CASE.err, CASE.log ) can be found.  Default "./logs"
-T STASHD: root directory where we write archived logs.  Default "./logs/stashed"
-L RUNLOGD: Run log directory or file. If directory, run log file is RUNLOGD/runlog.dat.  If filename 
    given, assume this is existing run log file.  Default is "./logs"
-y YAMLD: directory with YAML input files (named CASE.yaml).  Default "./yaml"
-Y: move (not copy) YAML files
-F EXPECTED_STATUS: Define expected status of runs
-c CQD: explicit path to cromwell query utility `cq` and `datatidy`
-m NOTE: A note added to run log file for each case
-D DATATIDY_ARGS: arguments passed to datatidy during registration

Runtidy performs the following task:
* `query`: Evaluate and print for each case
    - case, workflowId, path to run output log 
* `register`: write entry in run log and register with `runtidy`
* `stash`: move run output files and copy YAML config file to directory named after workflowID
* `finalize`: Run `register` and `stash` 

Cromwell generates two classes of output 
* Data output in workflowRoot directory. See `datatidy` for details 
* Run output files (CASE.*) in LOGD directory, consisting of Cromwell stdout and stderr
  (possibly log file generated by GNU `parallel`). 
`runtidy` is concerned with the run output files, which are used to obtain a WorkflowID for a given run.  

Stashing a run consists of moving the run output files (and possibly YAML file)
to a directory STASHD/WorkflowID.  This is done to clean output directory and
allow for multiple runs for one case (e.g. to restart failed run).Stashing or
finalizing a run twice will print a warning.  If this WorkflowID does not exist
in runlog file exit with an error, since not having this entry will make it
hard to map CASE to WorkflowID in future.  Stashing also copies or moves YAML
files to stash directory; if status is Succeeded the YAML is moved, copied
otherwise (-Y to always move YAML files).

Registering a run creates an entry in run log file; this file tracks which case
is associated with which Workflow ID.  Runs are stashed only when
they have completed execution, but can be registered any time any number of times.

A run log file has the following columns
    * `Case`
    * `WorkflowID`
    * `Status`
    * `StartTime`
    * `EndTime`
    * `Note` - optional, may indicate whether a restart, etc.

Finalizing involves registering with run log file, stashing, and also
registering data output using `datatidy`

By default, only runs with status (as obtained from `cq`) of `Succeeded` or
`Failed` are evaluated for `stash` and `finalize` tasks.  To stash and finalize
runs with some other status, EXPECTED_STATUS must be defined; then, all cases
must have a status (as obtained from `cq`) same as EXPECTED_STATUS. (This is to
help prevent inadvertant data loss from stashing running jobs)

All runs regardless of status are processed for `register` and `query` tasks.

If CASE is - then read CASE from STDIN.  If CASE is not defined, read from CASES_FN file.
`runtidy` script does not WorkflowIDs as arguments to define runs

This script relies on `cq` to get WorkflowID and status associated with each case
EOF

source cromwell_utils.sh

SCRIPT=$(basename $0)
SCRIPT_PATH=$(dirname $0)

TASK="query"
LOGD="./logs"       # where we find Cromwell run logs
STASHD="./logs/stashed"     # where we put stashed logs
RUNLOGD="./logs"    # Where we write runlog.dat

YAMLD="./yaml"
CASES_FN="dat/cases.dat"
QUIET=1

while getopts ":hdv1x:k:l:T:L:y:YF:c:m:D:" opt; do
  case $opt in
    h) 
      echo "$USAGE"
      exit 0
      ;;
    d)  # propagate to datatidy
      DRYRUN="d"
      QUIET=0   # print stuff out
      DATATIDY_ARGS="$DATATIDY_ARGS -d"
      ;;
    1)  # propagate to datatidy
      JUSTONE=1
      DATATIDY_ARGS="$DATATIDY_ARGS -1"
      ;;
    v) 
      QUIET=0
      ;;
    x)
      TASK="$OPTARG"
      ;;
    k) 
      CASES_FN="$OPTARG"
      ;;
    l) 
      LOGD="$OPTARG"
      ;;
    T) 
      STASHD="$OPTARG"
      ;;
    L) 
      RUNLOGD="$OPTARG"
      ;;
    y) 
      YAMLD="$OPTARG"
      ;;
    Y) 
      YAML_MV=1
      ;;
    F) 
      EXPECTED_STATUS="$OPTARG"
      ;;
    c) 
      CQD="$OPTARG"
      ;;
    m)
      NOTE="$OPTARG"
      ;;
    D) 
      DATATIDY_ARGS="$DATATIDY_ARGS $OPTARG"
      ;;
    \?)
      >&2 echo "Invalid option: -$OPTARG" 
      >&2 echo "$USAGE"
      exit 1
      ;;
    :)
      >&2 echo "Option -$OPTARG requires an argument." 
      >&2 echo "$USAGE"
      exit 1
      ;;
  esac
done
shift $((OPTIND-1))

if [ -z $CQD ]; then
    CQ="cq"
    DATATIDY="datatidy"
else
    CQ="$CQD/cq"
    DATATIDY="$CQD/datatidy"
fi

mkdir -p $LOGD
test_exit_status

# this allows us to get case names in one of three ways:
# 1: cq CASE1 CASE2 ...
# 2: cat cases.dat | cq -
# 3: read from CASES_FN file
# Note that if no cases defined, assume CASE='-'
if [ "$#" == 0 ]; then
    confirm $CASES_FN
    CASES=$(cat $CASES_FN)
elif [ "$1" == "-" ] ; then
    CASES=$(cat - )
else
    CASES="$@"
fi

# If RUNLOGD is an existing directory use that, and create runlog.dat if necessary
# elif RUNLOGD is an existing file use that,
# else error
if [ -d $RUNLOGD ]; then
    RUNLOG="$RUNLOGD/runlog.dat"
elif [ -f $RUNLOGD ]; then
    RUNLOG="$RUNLOGD"
else
    >&2 echo ERROR: Not a file or directory: $RUNLOGD
    exit 1
fi

# TODO- update with RUNLOG header
if [ ! -f $RUNLOG ]; then
    >&2 echo Creating new run log $RUNLOG
    # Write header
    printf "# Case\tWorkflowID\tStatus\tStartTime\tEndTime\tNote\n" > $RUNLOG
    test_exit_status
else
    >&2 echo Existing data log $RUNLOG
fi

function do_query {
    CASE=$1
# * `query`: Evaluate and print for each case
#     - case, workflowId, path to run output log 

    >&2 echo do_query is unimplemented
    exit 1
}
function do_register {
    CASE=$1

    STATUS=$( $CQ -V -q status $CASE )

    # CQL has all columns except for the note
    CQL=$( $CQ -q runlog $CASE ) 
    test_exit_status
    WID=$( echo "$CQL" | cut -f 2 )
    if [ "$WID" == "Unknown" ] || [ "$WID" == "Unassigned" ]; then
        continue
    fi

    RL=$( printf "$CQL\t$NOTE\n" )

    if [ "$DRYRUN" ]; then
        >&2 echo Dryrun: runlog = "$RL"
    else
        echo "$RL" >> $RUNLOG
    fi

}

# Stashing detail. For each case:
#  * Test if CASE.err, CASE.out, and CASE.yaml files exist.  
#    If any do not, test to see if stashed directory (based on WorkflowID) exists.
#    If it does not, print warning and continue to next case
#  * Obtain WorkflowID of case based on CASE.out.
#  * Obtain Status of WorkflowID based on call to `cq`
#    * if Status is not "Succeeded" print warning and continue to next case, unless FORCE_STATUS=1
#  * Check if STASHD/WorkflowID directory exists.  If it does, exit with an error
#  * Check if runlog has entry with WorkflowID.  If it does not, exit with an error
#  * Move LOGD/CASE.* to STASHD/WorkflowID
#  * If STATUS = Succeeded or YAML_MV is defined
#    * Move YAMLD/CASE.yaml to STASHD/WorkflowID
#    * otherwise copy YAMLD/CASE.yaml to STASHD/WorkflowID
function do_stash {
    CASE=$1

    OUTFN="$LOGD/$CASE.out"
    ERRFN="$LOGD/$CASE.err"
    YAMLFN="$YAMLD/$CASE.yaml"
    WID=$( $CQ -V -q wid $CASE ) 

    if [ ! -f $OUTFN ] || [ ! -f $ERRFN ] || [ ! -f $YAMLFN ]; then
    # Log files missing.  See if they've already been stashed
        if [ -d $LOGD/$WID ]; then
            >&2 echo $CASE already stashed 
        else
            >&2 echo WARNING: $CASE: Log/yaml files does not exist, skipping this case 
        fi
        return
    fi

    # WID may be unknown for various reasons, like error conditions.  Stashing requires that this
    # value be known; if it is not, print a complaint and go on
    if [ $WID == "Unknown" ]; then
        >&2 echo Warning: WorkflowID for $CASE is $WID.  Not stashing these logs, continuing
        return
    fi

    STATUS=$( $CQ -V -q status $CASE ) 
    test_exit_status
    if [ $STATUS == "Succeeded" ] || [ "$YAML_MV" ]; then
        YAML_CMD="mv"
    else
        YAML_CMD="cp"
    fi

    if ! grep -F -q $WID $RUNLOG ; then
        if [ ! "$DRYRUN" ]; then
            >&2 echo ERROR: $CASE \( $WID \) not found in $RUNLOG. Register run with \`runLogger.sh\` before stashing
            exit 1
        fi
    fi

    OUTD="$STASHD/$WID"
    if [ -d $OUTD ]; then
        >&2 echo WARNING: Stash directory exists: $OUTD
        >&2 echo Skipping this case
        return
    fi

    CMD="mkdir -p $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET

    CMD="mv $LOGD/$CASE.* $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET

    CMD="$YAML_CMD $YAMLD/$CASE.yaml $OUTD"
    run_cmd "$CMD" "$DRYRUN" $QUIET
}

# if expecting a given status, first pre-check to make sure all cases are of this status
# to do this.  Note this is alternative logic to datatidy, where testing during main loop
if [ ! -z $EXPECTED_STATUS ]; then
    DOCKET=""
    for CASE in $CASES; do
        STATUS=$( $CQ -V -q status $CASE )
        if [ "$STATUS" != "$EXPECTED_STATUS" ]; then
            >&2 echo ERROR: Status of case $CASE \( $STATUS \) differs from expected \( $EXPECTED_STATUS \)
            exit 2  # to distinguish status mismatch from garden variety errors
        fi
        DOCKET="$DOCKET $CASE"
        if [ $JUSTONE ]; then
            break
        fi
    done
    CASE=$DOCKET    #  CASE replenished to loop through all cases again
fi

for CASE in $CASES; do

    STATUS=$( $CQ -V -q status $CASE )

    case "$TASK" in
      "query")
        do_query $CASE  # TODO implement this
        ;;
      "register")
        do_register $CASE 
        ;;
      "stash")
        if [ -z $EXPECTED_STATUS ]; then
            if [ $STATUS != "Succeeded" ] && [ $STATUS != "Failed" ]; then
                continue
            fi
        fi
        do_stash $CASE 
        ;;
      "finalize")
        if [ -z $EXPECTED_STATUS ]; then
            if [ $STATUS != "Succeeded" ] && [ $STATUS != "Failed" ]; then
                continue
            fi
        else
            # If expected status is defined, pass this along to datatidy.  
            DATATIDY_ARGS="$DATATIDY_ARGS -F $EXPECTED_STATUS"   
        fi
        if [ ! -z "$NOTE" ]; then   # NOTE can have spaces, so escaping it is a pain
            $DATATIDY -m "$NOTE" $DATATIDY_ARGS -x original $CASE 
        else
            $DATATIDY $DATATIDY_ARGS -x original $CASE 
        fi
        test_exit_status
        do_register $CASE 
        do_stash $CASE
        ;;
      *)
        >&2 echo ERROR: Unknown task $TASK
        >&2 echo "$USAGE"
        exit 1
        ;;
    esac


    if [ $JUSTONE ]; then
        break
    fi

done

