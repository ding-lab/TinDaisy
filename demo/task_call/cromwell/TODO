Immediate TODO:

Consider about serial runs.  If analysis summary exists, do not overwrite - either append, or generate new one.


Step 4 should be cleaning of output directory per workflow ID.  There are several levels associated with this.
1. delete all staged data (inputs directory)
2. Delete staged and compress all step intermediate data
3. Delete all staged and step intermediate data
4. Delete all staged data, step intermediate data, and step final data (leave only final step as is)
5. Remove entire output directory

Cromwell output directory will be obtained from querying database

To test:
* Not certain parallel won't work. Do tmux first.  To wit,
  1. tmux new
  2. start docker
  3. run -J 4
-> This is being tested in ../cromwell.B.  Seems like it may be working...

---
* Need to be able to process output directories when .out file is lost, and just have WorkflowID (like C3L-00104)
* Need to be able to identify failed runs and clean them up
* need to see which steps are still running for a given case
  The following will return status of run_pindel
-> curl -s -X GET "https://genome-cromwell.gsc.wustl.edu/api/workflows/v1/9b018827-12df-477d-ac6d-d5d6a410db75/metadata?includeKey=&includeKey=&expandSubWorkflows=false" -H "accept: application/json" | jq -r '.calls.run_pindel[0].executionStatus'
  How to get status for all steps?

---
Other tasks

Note that $CWL is specified twice, in project_config and 2_
